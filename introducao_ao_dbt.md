# IntroduÃ§Ã£o ao DBT

Desenvolvido por: AbÃ­lio Nogueira <br>
Fonte principal: [Dbt Docs](https://docs.getdbt.com/docs/build/documentation)
# ğŸ§± 1. Conceitos de uma Stack Moderna para Pipeline de Dados

---

## ğŸ” Pipeline de Dados

Um pipeline de dados Ã© uma sequÃªncia de processos automatizados que captura, transforma e carrega dados de diversas fontes para um destino, normalmente com o objetivo de anÃ¡lise, visualizaÃ§Ã£o ou tomada de decisÃ£o.

### Etapas comuns:
- **IngestÃ£o:** captura de dados (de APIs, bancos, arquivos etc.)
- **TransformaÃ§Ã£o:** limpeza, enriquecimento e reestruturaÃ§Ã£o dos dados
- **Armazenamento e consulta:** envio para bancos de dados, data warehouses ou data lakes
- **Consumo:** dashboards, modelos de ML, relatÃ³rios

---

## ğŸ”„ ELT vs ETL

### ETL (Extract, Transform, Load):
- **ExtraÃ§Ã£o:** obtÃ©m dados da fonte
- **TransformaÃ§Ã£o:** limpa e organiza antes de armazenar
- **Carga:** envia os dados prontos ao destino

ğŸ§  **Usado quando:** hÃ¡ necessidade de transformar os dados antes de armazenar.

---

### ELT (Extract, Load, Transform):
- **ExtraÃ§Ã£o:** obtÃ©m dados da fonte
- **Carga:** carrega os dados brutos no destino
- **TransformaÃ§Ã£o:** transforma os dados **dentro do banco** (ex: via SQL)

ğŸ§  **Usado quando:** o banco de destino Ã© potente e permite transformaÃ§Ã£o rÃ¡pida (ex: Snowflake, BigQuery, DuckDB)

---

## âš™ï¸ Ferramentas de InserÃ§Ã£o

Essas ferramentas automatizam a **ingestÃ£o** de dados, conectando-se a APIs, arquivos ou bancos de dados.

### Exemplos:
- **Airbyte** â€“ cÃ³digo aberto, permite conectar diversas fontes e destinos
- **Fivetran** â€“ soluÃ§Ã£o paga com foco em ELT
- **Singer** â€“ especificaÃ§Ã£o para ingestÃ£o de dados via arquivos "tap" e "target"
- **Python personalizado** â€“ scripts para ingestÃ£o sob medida

---

## ğŸ”§ Ferramentas de Pipelines de Dados

SÃ£o usadas para **orquestrar** as etapas do pipeline (agendamento, monitoramento, dependÃªncias).

### Exemplos:
- **Prefect** â€“ pipelines com foco em simplicidade e observabilidade
- **Dagster** â€“ design modular, com foco em desenvolvimento e validaÃ§Ã£o
- **Airflow** â€“ robusto e altamente configurÃ¡vel, ideal para ambientes complexos
- **Luigi** â€“ bom para pipelines locais e dependÃªncias simples
- **Make / bash / crontab** â€“ soluÃ§Ãµes caseiras e simples para fluxos pequenos

---

## ğŸ§± Banco de Dados Colunares

Diferente dos bancos tradicionais (linha a linha), os bancos colunares armazenam os dados **por coluna**, o que permite otimizaÃ§Ãµes para consultas analÃ­ticas.

### ğŸ†š Banco de Dados Colunares vs Relacionais

| CaracterÃ­stica      | Relacional (row-based) | Colunar (columnar)       |
|---------------------|------------------------|--------------------------|
| Armazenamento       | Linha por linha        | Coluna por coluna        |
| Otimizado para      | Escrita, OLTP          | Leitura, OLAP            |
| Exemplos            | PostgreSQL, MySQL      | DuckDB, ClickHouse, BigQuery |

---

## ğŸ¦† DuckDB

DuckDB Ã© um banco de dados analÃ­tico **colunar**, projetado para rodar **localmente**, dentro do seu processo Python (sem servidor).

### Vantagens:
- Extremamente leve (sem necessidade de servidor)
- Suporte nativo a formatos como Parquet e CSV
- IntegraÃ§Ã£o direta com pandas, Arrow e NumPy
- Alta performance em queries analÃ­ticas
- Ideal para prototipaÃ§Ã£o e ambientes de desenvolvimento

---

## ğŸ§ª Formas de Uso do DuckDB

- Como banco **embutido** em scripts e notebooks
- Com arquivos locais `.csv`, `.parquet`, `.json`
- Para consultar **DataFrames diretamente** (sem gravar no disco)
- Como camada intermediÃ¡ria de anÃ¡lise antes de enviar para um warehouse

### Exemplos:
```python
import duckdb
import pandas as pd

df = pd.read_csv("dados.csv")
duckdb.query("SELECT * FROM df WHERE valor > 100").to_df()
```




# ğŸ§© 2. Utilizando o DBT (Data Build Tool)

---

## ğŸ“Œ O que Ã© o DBT?

DBT (Data Build Tool) Ã© uma ferramenta que permite aplicar princÃ­pios de engenharia de software Ã  transformaÃ§Ã£o de dados no ambiente de dados analÃ­ticos.

ğŸ¯ **PropÃ³sito:** Transformar dados jÃ¡ carregados em um banco de dados (ex: DuckDB, BigQuery, Redshift) usando **SQL modular, versionado e testado**.

---

## âš™ï¸ Como funciona o DBT?

1. VocÃª cria **models** em arquivos SQL, organizados por camadas (ex.: `staging/`, `intermediate/`, `marts/`).
2. DBT converte esses arquivos em SQL executÃ¡vel no warehouse, respeitando dependÃªncias (via `ref()`).
3. Gera documentaÃ§Ã£o visual, realiza testes de qualidade, cria lineage (linhagem) e suporta versionamento com Git.
4. NÃ£o Ã© ferramenta de ingestÃ£o ou visualizaÃ§Ã£o â€” foca na transformaÃ§Ã£o (`T` de ELT).

ğŸ¯ VocÃª **nÃ£o move dados com o DBT**, mas transforma **dados jÃ¡ existentes no banco**.

---

## â˜ï¸ Dbt Cloud vs ğŸ–¥ï¸ Dbt Core

| Item             | DBT Cloud                        | DBT Core (open source)         |
|------------------|----------------------------------|-------------------------------|
| Interface        | Web, com UI e agendador          | Linha de comando (CLI)        |
| Infraestrutura   | DBT executa na nuvem             | VocÃª executa localmente       |
| PreÃ§o            | Gratuito (limitado) / Pago       | Gratuito                      |
| Recursos extras  | Scheduler, logs, alertas, UI     | Totalmente manual             |
| Ideal para       | Equipes e ambientes gerenciados  | Aprendizado e pequenos projetos |

---

## ğŸ§± OrganizaÃ§Ã£o das camadas: raw â†’ staging â†’ intermediate â†’ serving

O DBT incentiva uma estrutura em **camadas**, baseada em boas prÃ¡ticas de modelagem de dados analÃ­ticos:


1. **Staging** (`models/staging/`)  
   - Prepara os dados "atomizados" vindos das fontes (raw), usando **sources**.  
   - Renomeia colunas, padroniza tipos e formatos.  
   - Serve de Ãºnica referÃªncia Ã s tabelas de origem, reduzindo acoplamento.  


2. **Intermediate** (`models/intermediate/`)  
   - Agrega lÃ³gica de negÃ³cio intermediÃ¡ria.  
   - Organiza os dados por grupo de negÃ³cio (ex.: `finance/`, `marketing/`).  
   - Geralmente possui verbos na nomenclatura (ex.: `int_payments_pivoted_to_orders.sql`)  


3. **Marts** (ou **Marts**) (`models/marts/`)  
   - Dados finais preparados para anÃ¡lise e relatÃ³rios.  
   - Combina dados processados para formar as entidades Ãºteis para o negÃ³cio. 

ğŸ“Œ Essa organizaÃ§Ã£o modulariza o projeto e facilita a manutenÃ§Ã£o e entendimento do fluxo de dados.

AlÃ©m dessas, tambÃ©m podem existir:
- **raw**â€” Dados integralmente copiados de outras fontes de dados, onde nÃ£o Ã© aplicada nenhuma alteraÃ§Ã£o.
- **utilities** â€” modelos utilitÃ¡rios reutilizÃ¡veis (ex.: tabela de datas), nÃ£o contÃªm dados de negÃ³cios propriamente ditos.  

---

## ğŸ”§ O que o DBT faz?

âœ… Transforma dados com SQL  
âœ… Controla dependÃªncias entre modelos  
âœ… Roda transformaÃ§Ãµes com versionamento (Git)  
âœ… Valida com **testes automatizados**  
âœ… Documenta todo o projeto com **interface navegÃ¡vel**  
âœ… Gera **lineage (linhagem)** de dados para rastrear o fluxo

---

## ğŸš« O que o DBT **nÃ£o faz**

â›” NÃ£o extrai dados de fontes (nÃ£o faz ingestÃ£o)  
â›” NÃ£o carrega dados para o banco (nÃ£o Ã© ETL completo)  
â›” NÃ£o cria dashboards ou relatÃ³rios  
â›” NÃ£o armazena dados em si  
â›” NÃ£o Ã© ferramenta de Machine Learning

---

## ğŸ“š DocumentaÃ§Ã£o com DBT

Com um Ãºnico comando (`dbt docs generate`), o DBT cria uma documentaÃ§Ã£o HTML com:

- DefiniÃ§Ã£o de cada modelo
- DescriÃ§Ã£o das colunas
- RelaÃ§Ãµes entre tabelas (lineage)
- Testes aplicados
- Seeds, snapshots, macros

ğŸ“ Ã‰ possÃ­vel acessar via navegador (`dbt docs serve`) ou publicar no DBT Cloud.

---

## âœ… Testes no DBT

DBT possui testes **integrados e customizados**, aplicados diretamente no SQL.

### Testes integrados (genÃ©ricos):
```yml
models:
  - name: vendas
    columns:
      - name: id_venda
        tests:
          - unique
          - not_null
```

# ğŸš€ 2.1. DBT AvanÃ§ado

Neste tÃ³pico, exploramos funcionalidades mais avanÃ§adas do DBT que tornam os projetos mais dinÃ¢micos, reutilizÃ¡veis e auditÃ¡veis: **macros**, **snapshots** e **seeds**.

---

## ğŸ§  2.1.1. Macros

### O que sÃ£o?
Macros sÃ£o **funÃ§Ãµes reutilizÃ¡veis** escritas em Jinja (um template engine para Python), usadas para gerar SQL dinamicamente dentro do DBT.

ğŸ” **Servem para:**
- Reduzir repetiÃ§Ã£o de cÃ³digo SQL
- Criar lÃ³gica condicional ou parametrizada
- Padronizar transformaÃ§Ãµes

---

### Exemplo bÃ¡sico de macro

ğŸ“ Arquivo: `macros/formatar_datas.sql`

```sql
{% macro formatar_data(coluna) %}
    date_trunc('day', {{ coluna }})
{% endmacro %}
```


```sql
SELECT
    {{ formatar_data("data_pedido") }} AS data_formatada
FROM {{ ref('stg_pedidos') }}
```

## ğŸ§¬ 2.1.2 Snapshots

### O que sÃ£o?

Snapshots sÃ£o usados para capturar mudanÃ§as histÃ³ricas em dados dimensionais, como SCDs (Slowly Changing Dimensions). Eles permitem rastrear como um registro mudou ao longo do tempo.

ğŸ” **Servem para:**
VocÃª tem uma tabela de clientes e deseja registrar cada vez que o endereÃ§o de um cliente mudar, mantendo o histÃ³rico.

### Exemplo bÃ¡sico de snapshot
ğŸ“ Arquivo: snapshots/clientes_snapshot.sql

```sql
{% snapshot clientes_snapshot %}

{{
  config(
    target_schema='snapshots',
    unique_key='id_cliente',
    strategy='check',
    check_cols=['nome', 'email', 'endereco']
  )
}}

SELECT * FROM {{ source('vendas', 'clientes') }}

{% endsnapshot %}

```

ğŸ“ dbt_project.yml (configuraÃ§Ã£o):

```yaml
snapshots:
  my_dbt_project:
    +target_schema: snapshots
    +strategy: check
```

## ğŸŒ± 2.1.3  Seeds

### O que sÃ£o?

Seeds sÃ£o arquivos CSV usados como tabelas estÃ¡ticas no projeto DBT. Ideal para dados pequenos e constantes como tabelas de referÃªncia, cÃ³digos de UF, calendÃ¡rios etc.

ğŸ” **Como funciona:**
1. Salve um CSV na pasta /seeds/

2. Execute dbt seed

3. O DBT converte o CSV em uma tabela no banco de dados


### Resumo 
```plaintext
macros/
â”œâ”€â”€ utilitarios.sql   # funÃ§Ãµes Jinja para SQL dinÃ¢mico

snapshots/
â”œâ”€â”€ clientes_snapshot.sql   # monitora mudanÃ§as histÃ³ricas

seeds/
â”œâ”€â”€ calendario.csv          # dados estÃ¡ticos
â”œâ”€â”€ tipo_produto.csv

```


# ğŸ—‚ï¸ 3. Estrutura de um Projeto DBT

Um projeto DBT Ã© organizado em uma estrutura de pastas e arquivos que promove boas prÃ¡ticas de engenharia de software, como modularidade, reutilizaÃ§Ã£o e testabilidade. Abaixo, detalhamos cada componente.

---

## ğŸ“‚ Estrutura de Pastas Principal

Um projeto DBT tÃ­pico tem a seguinte aparÃªncia:

```plaintext
meu_projeto_dbt/
â”œâ”€â”€ models/                 # Onde ficam os modelos de transformaÃ§Ã£o (SQL, Python)
â”œâ”€â”€ seeds/                  # Arquivos CSV com dados estÃ¡ticos
â”œâ”€â”€ tests/                  # Testes de dados personalizados (singulares)
â”œâ”€â”€ macros/                 # FunÃ§Ãµes reutilizÃ¡veis (Jinja + SQL)
â”œâ”€â”€ snapshots/              # ConfiguraÃ§Ã£o para capturar mudanÃ§as histÃ³ricas (SCD)
â”œâ”€â”€ dbt_project.yml         # Arquivo principal de configuraÃ§Ã£o do projeto
```

---

## ğŸ§¾ Arquivos de ConfiguraÃ§Ã£o

### `dbt_project.yml`
Ã‰ o coraÃ§Ã£o do projeto. Este arquivo define:
- **Nome do projeto** e versÃ£o.
- **Perfil de conexÃ£o** a ser usado (do arquivo `profiles.yml`).
- **Caminhos** onde o DBT deve procurar por cada tipo de recurso (`model-paths`, `seed-paths`, etc.).
- **ConfiguraÃ§Ãµes globais** para modelos, como materializaÃ§Ã£o (`table`, `view`, `incremental`).

**Exemplo:**
```yaml
name: 'meu_projeto_dbt'
version: '1.0.0'
profile: 'default' # Nome do perfil de conexÃ£o

# Define onde cada tipo de recurso estÃ¡ localizado
model-paths: ["models"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

# ConfiguraÃ§Ã£o padrÃ£o para todos os modelos dentro do projeto
models:
  meu_projeto_dbt:
    # Modelos na pasta staging serÃ£o materializados como views
    staging:
      materialized: view
    # Modelos na pasta marts serÃ£o materializados como tabelas
    marts:
      materialized: table
```

### `packages.yml`
Usado para declarar dependÃªncias de pacotes externos, como o `dbt-utils`, que oferece um conjunto de macros Ãºteis.

---

## `models/` â€“ A Camada de TransformaÃ§Ã£o

Esta Ã© a pasta mais importante, onde toda a lÃ³gica de transformaÃ§Ã£o de dados reside.

### OrganizaÃ§Ã£o em Camadas
Os modelos sÃ£o organizados em subpastas que representam as camadas do pipeline, conforme visto anteriormente:
- `models/staging/`: Modelos que fazem a limpeza e padronizaÃ§Ã£o inicial dos dados brutos (`sources`). Cada fonte de dados deve ter seu prÃ³prio modelo de staging.
- `models/intermediate/`: Modelos que aplicam lÃ³gica de negÃ³cio intermediÃ¡ria, como junÃ§Ãµes (`joins`) e agregaÃ§Ãµes complexas.
- `models/marts/`: Modelos finais, prontos para consumo por ferramentas de BI ou outras aplicaÃ§Ãµes. Representam entidades de negÃ³cio (ex: `dim_clientes`, `fct_pedidos`).

### Arquivos de Modelo (`.sql` e `.py`)
- **`.sql`**: A grande maioria dos modelos sÃ£o arquivos SQL. Neles, vocÃª usa as funÃ§Ãµes `{{ ref(...) }}` para criar dependÃªncias entre modelos e `{{ source(...) }}` para referenciar dados brutos.

  _Exemplo (`models/staging/stg_pedidos.sql`):_
  ```sql
  SELECT
      id AS id_pedido,
      id_cliente,
      status,
      valor AS valor_total
  FROM {{ source('loja', 'pedidos') }} -- Referencia a fonte de dados brutos
  ```

- **`.py`**: Para transformaÃ§Ãµes mais complexas que SQL nÃ£o suporta bem (requer um data warehouse compatÃ­vel como Snowflake, Databricks ou BigQuery).

### Arquivos de Propriedades (`.yml`)
Junto aos modelos, arquivos `.yml` sÃ£o usados para documentar, adicionar testes e definir configuraÃ§Ãµes especÃ­ficas.

- **DeclaraÃ§Ã£o de `sources`**: Mapeia as tabelas de dados brutos.
- **DescriÃ§Ã£o de `models` e colunas**: Adiciona metadados que aparecem na documentaÃ§Ã£o.
- **Testes genÃ©ricos**: Aplica testes prÃ©-definidos (`unique`, `not_null`, `accepted_values`, `relationships`).

_Exemplo (`models/staging/stg_loja.yml`):_
```yaml
version: 2

sources:
  - name: loja
    description: "Dados brutos do e-commerce."
    database: raw
    schema: public
    tables:
      - name: pedidos
      - name: clientes

models:
  - name: stg_pedidos
    description: "Modelo de staging para pedidos. Uma linha por pedido."
    columns:
      - name: id_pedido
        description: "Chave primÃ¡ria do pedido."
        tests:
          - unique
          - not_null
      - name: status
        tests:
          - accepted_values:
              values: ['entregue', 'enviado', 'processando', 'cancelado']
```

---

## Outras Pastas Essenciais

### `seeds/`
- **O que faz**: Armazena arquivos `.csv` com dados estÃ¡ticos (ex: tabela de feriados, lista de UFs, categorias de produtos).
- **Comando**: `dbt seed` carrega esses arquivos como tabelas no seu banco de dados.
- **Uso**: Podem ser referenciados em modelos usando a funÃ§Ã£o `{{ ref('nome_do_arquivo_seed') }}`.

### `tests/`
- **O que faz**: ContÃ©m testes de dados personalizados (chamados de "singulares"), que sÃ£o consultas SQL que devem retornar zero linhas para o teste passar.
- **Exemplo (`tests/assert_valor_total_positivo.sql`):**
  ```sql
  -- Se esta consulta retornar alguma linha, o teste falha.
  SELECT
      id_pedido,
      valor_total
  FROM {{ ref('stg_pedidos') }}
  WHERE valor_total < 0
  ```

### `macros/`
- **O que faz**: Define macros em Jinja, que sÃ£o pedaÃ§os de cÃ³digo SQL reutilizÃ¡veis. Ãštil para evitar repetiÃ§Ã£o e padronizar lÃ³gica.
- **Exemplo (`macros/formatar_moeda.sql`):**
  ```sql
  {% macro formatar_moeda(coluna) %}
      ({{ coluna }} / 100)::numeric(16, 2)
  {% endmacro %}
  ```
- **Uso no modelo**: `SELECT {{ formatar_moeda('valor_centavos') }} AS valor_reais FROM ...`

### `snapshots/`
- **O que faz**: Permite capturar o histÃ³rico de mudanÃ§as em uma tabela (Slowly Changing Dimensions - SCD Tipo 2).
- **Comando**: `dbt snapshot` executa a lÃ³gica para versionar os dados.
- **ConfiguraÃ§Ã£o**: Um arquivo `.sql` define a query e a estratÃ©gia para detectar mudanÃ§as (`check` ou `timestamp`).

# ğŸ“š 5. DocumentaÃ§Ã£o no DBT

A documentaÃ§Ã£o Ã© um dos pilares do dbt, permitindo que qualquer pessoa na organizaÃ§Ã£o entenda o que os dados significam, como sÃ£o transformados e qual a sua linhagem.

---

## ğŸ¯ DefiniÃ§Ã£o

A documentaÃ§Ã£o no dbt consiste em **metadados** escritos em arquivos `.yml` que descrevem seus recursos, como:
- **Models**: O que um modelo representa? Qual a sua finalidade?
- **Columns**: O que cada coluna significa? Qual o seu formato?
- **Sources**: De onde vÃªm os dados brutos? Com que frequÃªncia sÃ£o atualizados?
- **Tests**: Quais garantias de qualidade sÃ£o aplicadas a um determinado campo?

Ao executar o comando `dbt docs generate`, o dbt compila todo o conteÃºdo dos seus arquivos `.yml` e `.sql` em um **site estÃ¡tico, interativo e local**, que serve como um dicionÃ¡rio de dados e um mapa do seu pipeline.

---

## âœ¨ ImportÃ¢ncia

Manter a documentaÃ§Ã£o junto com o cÃ³digo de transformaÃ§Ã£o traz enormes benefÃ­cios:

- **Fonte Ãšnica da Verdade (SSOT)**: Centraliza o conhecimento sobre os dados, evitando planilhas e documentos desatualizados.
- **Data Discovery**: Facilita a descoberta de quais dados estÃ£o disponÃ­veis e como podem ser usados para anÃ¡lise.
- **ConfianÃ§a e GovernanÃ§a**: Aumenta a confianÃ§a nos dados ao expor a lÃ³gica de transformaÃ§Ã£o, os testes de qualidade e a linhagem de ponta a ponta.
- **ColaboraÃ§Ã£o**: Permite que analistas, engenheiros e stakeholders de negÃ³cio falem a mesma lÃ­ngua, usando as mesmas definiÃ§Ãµes.

---

## ğŸ“ LocalizaÃ§Ã£o dos Arquivos

Os arquivos de documentaÃ§Ã£o (`.yml`) sÃ£o flexÃ­veis, mas a convenÃ§Ã£o Ã© colocÃ¡-los **dentro da pasta `models/`**, prÃ³ximos aos recursos que eles descrevem.

Por exemplo, para um modelo `stg_pedidos.sql`, o ideal Ã© ter um arquivo `stg_pedidos.yml` na mesma pasta.

**Estrutura de exemplo:**
```plaintext
models/
â””â”€â”€ staging/
    â”œâ”€â”€ stg_clientes.sql
    â”œâ”€â”€ stg_pedidos.sql
    â””â”€â”€ stg_loja.yml  # Documenta todos os modelos e fontes da camada staging
```
Ã‰ possÃ­vel ter um arquivo `.yml` para cada modelo ou um arquivo que documenta vÃ¡rios modelos e fontes de uma sÃ³ vez, como no exemplo acima.

---

## ğŸ“ Exemplo Completo

Este exemplo de arquivo `yml` documenta uma fonte (`source`) e um modelo (`model`), incluindo descriÃ§Ãµes e testes.

ğŸ“ `models/staging/stg_ecommerce.yml`:
```yaml
version: 2

sources:
  - name: ecommerce_raw # Nome da fonte, usado em {{ source(...) }}
    description: "Dados brutos da plataforma de e-commerce."
    database: raw
    schema: public
    tables:
      - name: pedidos
        description: "Registra cada pedido feito na plataforma."
        columns:
          - name: id
            description: "Chave primÃ¡ria da tabela de pedidos."
            tests:
              - unique
              - not_null

models:
  - name: stg_pedidos # Nome do arquivo .sql (sem a extensÃ£o)
    description: "Modelo de staging para pedidos. Limpa e padroniza os dados brutos de pedidos. Uma linha por pedido."
    columns:
      - name: id_pedido
        description: "Chave primÃ¡ria do modelo de pedidos."
        tests:
          - unique
          - not_null
      - name: status_pedido
        description: "Status atual do pedido."
        tests:
          - accepted_values:
              values: ['processando', 'enviado', 'entregue', 'cancelado']
      - name: id_cliente
        description: "Chave estrangeira para o cliente que fez o pedido."
        tests:
          - relationships:
              to: ref('stg_clientes')
              field: id_cliente
```

---

## ğŸš€ Comandos Essenciais

1.  **`dbt docs generate`**: Compila o site da documentaÃ§Ã£o.
2.  **`dbt docs serve`**: Inicia um servidor web local para navegar pela documentaÃ§Ã£o gerada.


# ğŸ“ 6. Comandos Mais Frequentes do DBT

Aqui estÃ£o os comandos mais comuns que vocÃª usarÃ¡ no seu dia a dia com o dbt Core:

- **`dbt run`**: Executa todos os modelos na sua pasta `models`. Ã‰ o comando principal para rodar suas transformaÃ§Ãµes.
  - **`dbt run --select <nome_do_modelo>`**: Executa um modelo especÃ­fico.
  - **`dbt run --select staging`**: Executa todos os modelos em uma pasta.
  - **`dbt run --full-refresh`**: ForÃ§a a recriaÃ§Ã£o de modelos incrementais.

- **`dbt test`**: Executa todos os testes de dados definidos no seu projeto (genÃ©ricos e singulares).
  - **`dbt test --select <nome_do_modelo>`**: Testa apenas um modelo especÃ­fico.

- **`dbt build`**: Um atalho que executa `dbt run`, `dbt test`, `dbt seed` e `dbt snapshot` em uma Ãºnica etapa, na ordem correta de dependÃªncias.

- **`dbt compile`**: Compila o seu cÃ³digo Jinja para SQL puro, sem executÃ¡-lo. Ãštil para depuraÃ§Ã£o.

- **`dbt seed`**: Carrega os arquivos CSV da sua pasta `seeds` como tabelas no seu data warehouse.

- **`dbt snapshot`**: Executa os snapshots para capturar o histÃ³rico de mudanÃ§as nos seus dados.

- **`dbt docs generate`**: Gera o site de documentaÃ§Ã£o do seu projeto.

- **`dbt docs serve`**: Inicia um servidor web local para visualizar a documentaÃ§Ã£o gerada.

- **`dbt deps`**: Baixa as dependÃªncias de pacotes listadas no seu arquivo `packages.yml`.

- **`dbt clean`**: Remove as pastas `target/` e `dbt_packages/`, limpando os artefatos de compilaÃ§Ã£o.

- **`dbt debug`**: Ajuda a diagnosticar problemas de conexÃ£o com o seu banco de dados.
